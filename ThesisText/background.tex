\chapter{Background}
\label{sec:back}

% =============================================================================
\section{E-Learning and Learning Management Systems}
\label{sec:elearning_and_lms}

Recently, E-Learning has been rising in popularity as a solution for the
delivery of training. Institutions such as universities and companies have
successfully implemented E-Learning to bring course content and evaluation to
students, and to deliver training to employees remotely. This has been made
possible by the advances in technology and the increasing use of the Internet.

E-Learning is usually provided over the Internet using platforms
called~\gls{lms}. Examples of~\gls{lms} include Moodle, Blackboard Learn, D2L,
among others. These platforms organize users by separating them into roles such
as Professors and Students or Authors and Learners. The Professors or Authors
are the users who organize courses in universities or training in companies,
create and publish content, perform evaluation of students, etc. Students or
Learners are the users which actually perform the training and follow courses
in the platforms.

A typical~\gls{lms} contains various data entries which are stored in a
database. Information on users, such as their names, usage logs, roles, forum
messages, are generated by the systems and kept in their databases.

Resources and activities, as well as the logs detailing their usage, are also
kept in a database. The usage of these systems by professors and students
generates entries.~\cite{ind_010, ind_011, ind_013}

In the specific case of Moodle, content is divided into courses. Each Moodle
course represents a course from a University or similar learning institution.

The contents of a course may be resources such as PDF files, links, media such
as images, videos, etc. These resources should be guides for students achieve
their objectives in learning, or should be resources needed for the student to
perform certain tasks. A course may also have activities. Activities may be,
for example, projects that a student needs to complete before a given deadline.
Activities may also be quizzes made to students over Moodle. These quizzes may
be used for evaluation.

Course also have forums, in which professors and students can exchange messages
which are relevant to the topics at hand.

A course is overseen by a group of Professors who will publish resources and
create activities. Students will use the resources and perform the
activities.~\cite{ind_014, ind_015}

% =============================================================================
\section{Data Mining}

Current computational systems produce and store large amounts of data. This
data may represent anything, such as the sales records in a large commercial
chain, the usage telemetry on a popular web service, or even the registers of
some scientific survey. Data is usually rich in features. For example, the data
from the sales records would contain information on which items were sold and
in what quantity, to whom they were sold, on what date, and so on.

Data Mining aims at finding patterns in data by looking at the different
features of the data entries. These patterns allows us to make non trivial
assumptions in data.~\cite{book_dm_practical}

Data is usually stored in databases which may follow different paradigms and
have different architectures. But generally, we refer to data entries as
datasets. We also refer to a group of datasets as a data repository.

To find patterns in data, models are trained either using supervised or
unsupervised learning. The following sections describe these concepts and
introduce models from both.

\subsection{Supervised Learning}

Supervised learning is done when data made up of a collection of labeled
objects which have a list of features and a label, usually called class. The
idea is that a model is trained using instances from labeled data in order to
correctly classify unlabeled instances later.

There exist several supervised learning models, but in this project we use only
two. They are Decision Trees and Naive Bayes
Classifiers.~\cite{book_ml,book_dm_practical}

\subsubsection{Decision Trees}

Decision trees are a model that make use of a tree to classify an object. The
model works by sorting an object down the tree, taking a single feature into
account on each node of the tree. The branches on each node are the possible
values of the feature being taken into account on that node. The leafs of the
tree assign a class to the object.

Decision trees are generally best suited for situations where the data has
discrete values. This is the case in this project, since many features are
either integer numbers with a limited range of values, or strings and
enumerated types which are nominal in nature.

There are a few algorithms used to train these model. They are ID3, C4.5 which
is an optimization of ID3, and CART.~\cite{book_ml,book_dm_practical}

\subsubsection{Naive Bayes Classifiers}

Naive Bayes Classifiers are probabilistic models which are based on Bayesian
Networks. A Bayesian Network is a graph that describes directional the
dependencies between features of objects. Those features are described as
random variables.

The models that make up a Naive Bayes Classifier are a particular case of
Bayesian Networks. In these models there is a single node of the network which
is the class of the object. Every feature depends directly on the class and
only on the class.

Each model essentially describes a conditional probability distribution like:

\begin{equation} \label{eq:prob} P(\; x_1, \; \dots, \; x_n \; | \; C),
\end{equation}

where $ C $ is the class of the object and $ x_1, \; \dots, \; x_n $ are the
features of it. The model is able to classify an object by directly applying
the Bayes Theorem to the distribution, obtaining a value a $ C $.

There are different types of Naive Bayes Classifier. Each type is adequate for
different types of features. For example, Guassian Naive Bayes Classifier
describe relations between variables, like equation~\ref{eq:prob}, as normal
distributions. Bernoulli Naive Bayes Classifier are used if the features are
boolean.

Multinomial Naive Bayes Classifier are used when the data has discrete values
and is nominal in nature. This model is used in this project because the data
it deals with is discrete and nominal.~\cite{book_ml,book_dm_practical}

\subsection{Unsupervised Learning}

Unsupervised learning deals with data that is unlabeled. One approach to
unsupervised learning is clustering. The objective of clustering is to find
groups of unlabeled objects. A group would ideally have objects which features
are similar to objects within that group, and dissimilar to objects in other
groups.

One difficulty of clustering is to find the number of clusters that optimally
divide the data. Some algorithms take a number of clusters as an arguments,
while others are able to find an optimal value.

By it's own nature, it may not be possible to find clusters in data, that is,
there may not be any great division of objects given their features in a given
dataset. After executing clustering algorithms a performance measure is used to
determine if that division is good or not.

In this project, the performance measure used is called Silhouette Score.
Silhouette score yields a value between -1 a 1. The interpretation given to
this value is that higher values mean that objects are correctly placed in
their clusters, lower values mean the objects are in the wrong clusters. Values
near zero indicate that the clusters overlap.~\cite{book_ml,book_dm_practical}

\subsubsection{K-Means}

K-Means is an clustering algorithm that find $ K $ clusters in data. The $ K $
variable is given to the algorithm as an argument, hence the name K-Means. The
algorithm works by creating $ K $ random points based on the features of the
data. The algorithm then iterates updating the location of those points until
they converge.~\cite{book_ml,book_dm_practical}

\subsubsection{Affinity Propagation}

Affinity Propagation is another clustering algorithm, but this one does not
take a number of clusters as an argument. This algorithm finds the optimal
number of clusters.~\cite{book_ml,book_dm_practical}

\subsection{Cross Validation}

The model used in this project and described in this section always go through
two processes. Training and testing. To do this two sets of data are needed,
one for each process. Data for the two processes is usually taken from the same
dataset in different proportions. For example, some projects may take 75\% or
90\% of the data to do training, and use the remainder to test.

Testing a model with different objects then the ones used in training is very
important. This is because a model, while training, will learn the very
specific details of that data and may over fit. When over fitted, a model will
not work for general examples of the data for which it was trained and will
only ``remember'' training data instead.

A way of dividing a dataset into training and testing sets is to do Cross
Validation. Cross Validation divides the data into $ N $ folds. From the
original $ N $ folds, a single one is taken for testing and the model is
trained with the remaining $ N - 1 $ folds.

A model is trained and tested $ N $ times, each time with a different fold
taken for testing. Like this we get $ N $ different executions for the same
dataset and same model and we are able to compare the best, worst, and average
scenario in terms of training and testing.~\cite{book_dm_practical}

% =============================================================================
\section{Educational Data Mining}

Educational Data Mining, \gls{edm}, refers to the act of applying Data Mining
techniques to educational data. Educational data refers to data which origin is
in the act of teaching and training, in the activities of professors and
students, results of evaluation, and so on. In this project, the origin of data
is the University of Évora's Moodle.

The main objective of~\gls{edm} is to extract meaningful information from
educational data like web logs. It is not trivial to do so without advance Data
Mining techniques. \gls{edm}, therefore, aims at training models based on
education data for a variety of tasks.

One such example of~\gls{edm} Data Mining tasks is too predict student grades
based features from the students themselves, the courses they are undertaking,
and their activity in a~\gls{lms}. By training such models, professors can make
decisions about how courses are organized regarding students success. For
example, a certain number of activities in a given course may be beneficial to
it's success because it keeps students engaged, but any number of activities
more might not make a difference.~\cite{ind_001, ind_002, ind_005}

These models also detect students which may have greater difficulty completing
certain courses, or be used to predict how many students will complete a
certain class.~\cite{ind_007, ind_008}.

In~\cite{ind_001}, some models are trained in order to predict student grades.
The tasks described in the paper are classification tasks, in which a student
is assigned to a given class corresponding to their success in courses based on
their usage of a~\gls{lms} platform. The classes available are Excellent, Good,
Pass, and Fail.

The dataset used in~\cite{ind_001} contained the fields in
table~\ref{tab:ind_001_004_fields} and was made from registers of 438 students
in 7 different courses.

\begin{table}[h!]
    \centering

    \begin{tabular}{l l}
        Field name                       & Description                                    \\ \hline
        \texttt{course}                  & Identification number of the course.           \\
        \texttt{n\_assigment}            & Number of assignments done.                    \\
        \texttt{n\_quiz}                 & Number of quizzes taken.                       \\
        \texttt{n\_quiz\_a}              & Number of quizzes passed.                      \\
        \texttt{n\_quiz\_s}              & Number of quizzes failed.                      \\
        \texttt{n\_posts}                & Number of messages sent to the forum.          \\
        \texttt{n\_read}                 & Number or messages read on the forum.          \\
        \texttt{total\_time\_assignment} & Total time used on assignments.                \\
        \texttt{total\_time\_quiz}       & Total time used on quizzes.                    \\
        \texttt{total\_time\_forum}      & Total time used on forum.                      \\
        \texttt{mark}                    & Final mark the student obtained in the course. \\
    \end{tabular}

    \caption
        [Features in experiment~\cite{ind_001} and~\cite{ind_004}]
        {Features in experiment~\cite{ind_001} and~\cite{ind_004}.}

    \label{tab:ind_001_004_fields}
\end{table}

The used models are Statistical Classifiers, Decision Trees, Association Rules,
and Neural Networks. After training, performance measures are calculated using
test data. The best models were found to be decision trees according to the
calculated global percentage of correctly classified students.

The same experiment described in~\cite{ind_001} is also described
in~\cite{ind_004} with the same models, data, and results.

Similar models to before are used in~\cite{ind_005}. It is observed again that
Decision Trees have the best performance. Table~\ref{tab:ind_005_fields} shows
the data from~\cite{ind_005}. The experiments were made on data from 824
students in 11 courses.

\begin{table}[h!]
    \centering

    \begin{tabular}{l l}
        Field name                & Description                                              \\ \hline
        \texttt{UserName}         & Name of User                                             \\
        \texttt{CourseName}       & Name of the Course                                       \\
        \texttt{ResourceView}     & Number of Coursware and Other Supporting Materials Views \\
        \texttt{VirtualClassroom} & Number of Virtual Classroom Participations               \\
        \texttt{ArchiveView}      & Number of Archive Views                                  \\
        \texttt{ForumRead}        & Number of Forum Reads                                    \\
        \texttt{ForumPost}        & Number of Forum Posts                                    \\
        \texttt{DiscussionRead}   & Number of Discussion Reads                               \\
        \texttt{DiscussionPost}   & Number of Discussion Responses                           \\
        \texttt{AssignmentView}   & Number of Assignments Views                              \\
        \texttt{AssignmentUpload} & Number of Assignment Answer Uploads                      \\
        \texttt{FinalGrade}       & Final Grades                                             \\
    \end{tabular}

    \caption
        [Features in experiment~\cite{ind_005}]
        {Features in experiment~\cite{ind_005}.}

    \label{tab:ind_005_fields}
\end{table}

Neural networks are used in~\cite{ind_003} and~\cite{ind_006} for similar
purposes. In~\cite{ind_003} a neural network is used on a dataset with 116
entries. Each entry is made from 25 features and represents the results of
placements tests made to students. There are 5 outputs to the network, one for
each possible grade. The paper claims correctly classified rates of over 90\%
in some trained networks while most are just above 80\%. This shows how neural
networks can be used in this type of problems.

In~\cite{ind_006}, networks are trained from Moodle logs. The data from the
logs are structured in a slightly different way then the previous studies. The
features of this data are shown in table~\ref{tab:ind_006_fields}.

\begin{table}[h!]
    \centering

    \begin{tabular}{l}
        Description \\ \hline
        Full name of the student. \\
        Number of times that has been officially registered in the subject. \\
        Number of examination sessions. \\
        Mark in numerical format. \\
        Total of accesses (of any type) made to the Moodle system during course 2005/2006. \\
        Total of accesses to “resource view” \\
        Percentage of “resource view” accesses from the total accesses. \\
        Number of different “resource view”of each type (theoretical, examples, etc.) have been visited. \\
        Percentage of the resources of each type (theoretical, examples, etc.) sights. \\
        Segmentation of the number of accesses in every month of the year. \\
        Segmentation per month of the percentage of accesses. \\
    \end{tabular}

    \caption
        [Features in experiment~\cite{ind_006}]
        {Features in experiment~\cite{ind_006}.}

    \label{tab:ind_006_fields}
\end{table}

The data is extracted from 240 students. The number of courses is not
specified. Some trained networks are able to achieve 80\% of correctly
classified instances, while most achieve a value over 70\%.

Beyond the classification tasks, clustering may be used in educational data.
The overall objective of clustering is to find groups of similar objects
within data. In the context of~\gls{edm} that may mean looking for groups of
students with similar characteristics without their Moodle usage habits.~\cite{ind_007,ind_008}

% =============================================================================
\section{Data Mining Tools}

The practical component of this project was developed entirely using Python and
some Python libraries. The version of CPython used was version 3.5.2. The
python libraries Pandas, version 0.19.2, was used for statistical analysis,
exploration, and preprocessing. The library SciKit-Learn, version 0.18.1, was
used to perform Data Mining tasks. SciKit-Learn uses Numpy and Scikit, in
versions 1.11.3 and 0.18.1 respectively. To output some graphs, the python
library Mat Plot Lib, version 1.5.4, was used.

Decision trees and Bayesian Networks were used in this project. The algorithm
to train decision trees, implemented in the SciKit-Learn library, is an
optimized version of the CART algorithm~\cite{web_scikit_trees}. Bayesian
Networks are used in Naive Bayes tasks. The algorithm to train such models,
also implemented in SciKit-Learn, is Multinomial Naive
Bayes~\cite{web_scikit_bayes}.

Clustering is done using K-Means~\cite{web_scikit_kmeans} and Affinity
Propagation~\cite{web_scikit_affinity}. Both algorithms are implemented in
SciKit-Learn.
